{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7c4591f-962f-42bc-b40a-b0d019f36438",
   "metadata": {},
   "source": [
    "# Objective: This model is used for classification of STFT array\n",
    "## Description: Since the model is very large use of GPU is preferable, I have included the GPU usage also."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67cd947-fcdb-469f-9577-7044dc15fdc5",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c9ccea-bff5-42c2-bf06-f7c442ac79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from torch.utils.data import TensorDataset\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3116246-c230-4263-aa47-f255a8b25980",
   "metadata": {},
   "source": [
    "### Saving the combined STFT outputs to numpy array type file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf0b110-5131-4463-80fa-6bdcd899b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir = \"C:\\\\Users\\\\vinay\\\\Downloads\\\\FEIS_v1_1\\\\augmented_wavs\"\n",
    "folder_count = 1\n",
    "labels = ['f', 'fleece', 'goose', 'k', 'm', 'n', 'ng', 'p', 's', 'sh', 't', 'thought', 'trap', 'v', 'z', 'zh']\n",
    "dataset = []\n",
    "dataset_labels = []\n",
    "for subdir, dirs, files in os.walk(rootdir):\n",
    "    if subdir == \"C:\\\\Users\\\\vinay\\\\Downloads\\\\FEIS_v1_1\\\\wavs\\\\\" + f'{folder_count:02d}' + \"\\\\combined_wavs\":\n",
    "        folder_count += 1\n",
    "        if folder_count == 5:\n",
    "            folder_count += 1\n",
    "        continue\n",
    "    elif subdir == \"C:\\\\Users\\\\vinay\\\\Downloads\\\\FEIS_v1_1\\\\wavs\\\\chinese-1\":\n",
    "        break\n",
    "    else:\n",
    "        count = 0\n",
    "        for file in files:\n",
    "            dummy = file.replace(\"_\", \".\")\n",
    "            file_name_list = dummy.split('.')\n",
    "            file_path = subdir + \"\\\\\" + file\n",
    "            samplerate, data = wavfile.read(file_path)\n",
    "            f, t, Zxx = signal.stft(data, samplerate, window='boxcar', nperseg=512, nfft=512, noverlap=103)\n",
    "            Zxx = Zxx.reshape((1, Zxx.shape[0], Zxx.shape[1]))\n",
    "            dataset.append(abs(Zxx))\n",
    "            dataset_labels.append(labels.index(file_name_list[0]))\n",
    "\n",
    "dataset = np.array(dataset)\n",
    "dataset_labels = np.array(dataset_labels)\n",
    "np.save(\"C:\\\\Users\\\\vinay\\\\Downloads\\\\FEIS_v1_1\\\\dataset.npy\", dataset)\n",
    "np.save(\"C:\\\\Users\\\\vinay\\\\Downloads\\\\FEIS_v1_1\\\\dataset_labels.npy\", dataset_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b1b70b-679a-4dd3-912b-a8e8f3ff88d5",
   "metadata": {},
   "source": [
    "### Loading the STFT dataset from local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7e2a54-45c1-405d-9322-fb434ae64842",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(\"C:\\\\Users\\\\vinay\\\\Downloads\\\\FEIS_v1_1\\\\dataset.npy\")\n",
    "dataset_labels = np.load(\"C:\\\\Users\\\\vinay\\\\Downloads\\\\FEIS_v1_1\\\\dataset_labels.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89480511-edcb-40e6-80af-586c744b7ebb",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244cd10-e2c7-498e-b9a0-dd467d8aa166",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(dataset, dataset_labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8310df72-88a7-49a5-aeaa-f4ce2f991cba",
   "metadata": {},
   "source": [
    "### Convert data to tensor and merging the data with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b8c658-ecb6-41a0-9a94-297de1106a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.Tensor(X_train) # transform to torch tensor\n",
    "y_train_tensor = torch.Tensor(y_train)\n",
    "y_train_tensor = y_train_tensor.type(torch.LongTensor)\n",
    "\n",
    "my_dataset = TensorDataset(X_train_tensor,y_train_tensor) # create your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa1e2bf-cc65-45dd-9969-436bf6e8f42d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2371735f-7f10-48f9-a962-1b35b3467693",
   "metadata": {},
   "source": [
    "### Splitting training data into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441ec0f3-3e06-4787-9253-572d07eb1a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 8\n",
    "\n",
    "train_dl = DataLoader(my_dataset, batchsize, shuffle=True, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a1f929-4e2b-4e3f-9e55-c4f9efebda7a",
   "metadata": {},
   "source": [
    "### displaying one batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab484a-119a-49dd-8f50-305820f69a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(dl):\n",
    "    for images, label in dl:\n",
    "        fig, ax = plt.subplots(figsize=(12,6))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=16).permute(1,2,0))\n",
    "        break\n",
    "\n",
    "show_batch(train_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42464e69-ef88-4292-b352-7855a30e094c",
   "metadata": {},
   "source": [
    "### Training, Validation step. Accuracy function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f05867d-feb4-45a0-9e52-1ffb2d7fb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        stft_tensor, labels = batch\n",
    "        out = self(stft_tensor)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        stft_tensor, labels = batch\n",
    "        out = self(stft_tensor)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)\n",
    "        return {'loss': loss, 'acc': acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()\n",
    "        batch_accs = [x['acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()\n",
    "        return {'loss': epoch_loss.item(), 'acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], train_loss: {:.4f}, train_acc: {:.4f}\".format(epoch, result['train_loss'], result['train_acc']))\n",
    "    \n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033a81ad-0d95-4606-bf0a-c3e766da0e57",
   "metadata": {},
   "source": [
    "### CNN model defining layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cdadf3-80db-4db3-aad3-36225900dfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(ClassificationBase):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Conv2d(1,8,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8,16,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(16,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,32,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Conv2d(32,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64,64,kernel_size=3,stride=1,padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(26624, 8196),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8196, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,16)\n",
    "        )\n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)\n",
    "\n",
    "model = CNNModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0c73e5-dd09-439b-a9d5-84819d1bbf9d",
   "metadata": {},
   "source": [
    "### Checking for GPU, sending data if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735a6f4-9494-44e1-9824-d054fd31b811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701df85-e28f-45ad-bdba-8bcc87c7fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aad9ab-fc5a-4b6c-91c3-edd5ec78af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "to_device(model, device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e331f9e0-757c-4579-9881-2b489e39f1b4",
   "metadata": {},
   "source": [
    "### Initializing fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb49665-920d-4121-9e88-5990a53d9e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval() # testing the model\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_loader, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), lr) # explicitly telling it what parameters (tensors) of the model it should be updating i.e. weight and biases\n",
    "    for epoch in range(epochs):\n",
    "        #training phase\n",
    "        model.train() # tells your model that you are training the model; model.eval() or model.train(mode=False) to tell that you are testing.\n",
    "        train_losses = []\n",
    "        train_acc = []\n",
    "        result = {}\n",
    "        for batch in train_loader:\n",
    "            loss, acc = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            train_acc.append(acc)\n",
    "            loss.backward() # The gradients are \"stored\" by the tensors themselves once called backward on the loss\n",
    "            optimizer.step() # makes the optimizer iterate over all parameters it is supposed to update and use their internally stored grad to update their values.\n",
    "            optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor's to zero.\n",
    "        #validation phase\n",
    "        #result = evaluate(model, train_loader)\n",
    "        result['epoch'] = epoch\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['train_acc'] = torch.stack(train_acc).mean().item()\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eceb5f-5265-41b7-9b7a-1bf74102912d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = to_device(CNNModel(), device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e2d6ce-8441-4f2f-bec1-506661ce235a",
   "metadata": {},
   "source": [
    "### Training the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85194660-2baa-415a-b3ae-79e1a452bfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "opt_func = torch.optim.Adam\n",
    "lr = 0.001\n",
    "\n",
    "history = fit(num_epochs, lr, model, train_dl, opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e55711-644e-42c8-b46e-de10ccac4ebd",
   "metadata": {},
   "source": [
    "### printing history of model of model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bdfc91-8624-47a2-a037-e93606107107",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# convert the history.history dict to a pandas DataFrame:     \n",
    "hist_df = pd.DataFrame(history)\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec76ad7f-f1c2-4fdc-88d7-a743cac6c21f",
   "metadata": {},
   "source": [
    "### Saving model history to csv file, this command specifically for google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b7b860-5ed3-4f11-8b0c-3b7f0852f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_df.to_csv('model_acc_loss_4.csv')\n",
    "!cp model_acc_loss_4.csv \"/content/gdrive/MyDrive/Colab Notebooks/EE626P_PGP/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386140fe-81a5-4be9-9a43-d8136d94d865",
   "metadata": {},
   "source": [
    "### Since the PyTorch does not have summary command using external library for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9f121a-bcc5-4bf2-a389-00d0b4202bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638c70f-dc1d-481a-a9b6-fb136f0ff4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, (1,257,109))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa806f-8ad5-4a55-bde5-90be608fe3fd",
   "metadata": {},
   "source": [
    "### Plotting training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c664406-9177-4731-bc2e-e8f9fdd186a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['train_acc'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    #plt.title('Accuracy vs. No. of epochs');\n",
    "\n",
    "plot_accuracies(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b31b66-9e48-4dd2-9ffb-5e557c6f2140",
   "metadata": {},
   "source": [
    "### Plotting training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8e6750-ee61-4a25-b790-f2862546c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    #val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    #plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training'])\n",
    "    plt.title('Loss vs. No. of epochs')\n",
    "\n",
    "plot_losses(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029037c9-85e2-484a-8cfe-2ddb096fafd8",
   "metadata": {},
   "source": [
    "### Convert data to tensor and merging the data with label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e0c6a0-5a79-4668-8832-08c2587a346c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tensor = torch.Tensor(X_test) # transform to torch tensor\n",
    "y_test_tensor = torch.Tensor(y_test)\n",
    "y_test_tensor = y_test_tensor.type(torch.LongTensor)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor,y_test_tensor) # create your dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba8d14-73c4-40a8-9407-740a7d5f1c73",
   "metadata": {},
   "source": [
    "### Testing the model for testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334e80c-a301-46ff-ae03-3b8d513c7930",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = DataLoader(test_dataset, batchsize, shuffle=True, num_workers=2, pin_memory=True)\n",
    "test_dl = DeviceDataLoader(test_dl, device)\n",
    "result = evaluate(model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eec4cc3-2750-4bdb-b17b-d9aab42dbc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"test data loss and accuracy is\", result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a776e7-99dd-4a0d-94a7-bda54319f237",
   "metadata": {},
   "source": [
    "### Predicting a random array from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf2c12f-54a2-4621-b108-8a76019f3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "    return preds[0].item()\n",
    "\n",
    "img, label = test_dataset[0]\n",
    "print('Label:', label, ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac62b57d-e863-483d-a042-bcc36d894985",
   "metadata": {},
   "source": [
    "### Confusion matrix for testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8108050-255c-4204-ac58-af75af709622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in test_dl:\n",
    "    for img in inputs:\n",
    "        y_pred.append(predict_image(img, model))\n",
    "    y_true = y_true + labels.tolist()\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cf_matrix, display_labels=['f', 'fleece', 'goose', 'k', 'm', 'n', 'ng', 'p', 's', 'sh', 't', 'thought', 'trap', 'v', 'z', 'zh'])\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "#sn.heatmap(cmd, annot=True)\n",
    "cmd.plot(ax=ax)\n",
    "#plt.savefig('output.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d36a9-e691-488a-98f7-113cc270ae85",
   "metadata": {},
   "source": [
    "### Confusion matrix for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d837b3aa-f84d-4586-9009-67418e0ae1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in train_dl:\n",
    "    for img in inputs:\n",
    "        y_pred.append(predict_image(img, model))\n",
    "    y_true = y_true + labels.tolist()\n",
    "\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "cmd = ConfusionMatrixDisplay(cf_matrix, display_labels=['f', 'fleece', 'goose', 'k', 'm', 'n', 'ng', 'p', 's', 'sh', 't', 'thought', 'trap', 'v', 'z', 'zh'])\n",
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "#sn.heatmap(cmd, annot=True)\n",
    "cmd.plot(ax=ax)\n",
    "#plt.savefig('output.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
